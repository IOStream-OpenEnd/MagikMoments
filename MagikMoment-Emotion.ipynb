{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras.applications.imagenet_utils import decode_predictions\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "from keras.layers import merge, Input\n",
    "from keras.models import Model\n",
    "from keras.utils import np_utils\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "cur_dir = os.getcwd()\n",
    "path = cur_dir + '/emotion'\n",
    "folders = os.listdir(path)\n",
    "\n",
    "img_data_list=[]\n",
    "\n",
    "for _ in folders:\n",
    "\timg_list=os.listdir(path+'/'+ _)\n",
    "\tfor img in img_list:\n",
    "\t\timg_path = path + '/'+ _ + '/'+ img\n",
    "\t\timg = image.load_img(img_path, target_size=(224, 224))\n",
    "\t\tx = image.img_to_array(img)\n",
    "\t\tx = np.expand_dims(x, axis=0)\n",
    "\t\tx = preprocess_input(x)\n",
    "\t\timg_data_list.append(x)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "img_data = np.array(img_data_list)\n",
    "\n",
    "print (img_data.shape)\n",
    "\n",
    "img_data=np.rollaxis(img_data,1,0)\n",
    "print (img_data.shape)\n",
    "img_data=img_data[0]\n",
    "print (img_data.shape)\n",
    "\n",
    "num_classes = 4\n",
    "num_of_samples = img_data.shape[0]\n",
    "labels = np.ones((num_of_samples,),dtype='int64')\n",
    "\n",
    "labels[0:202]=0\n",
    "labels[202:404]=1\n",
    "labels[404:606]=2\n",
    "labels[606:]=3\n",
    "\n",
    "\n",
    "names = ['angry','happy','neutral','sad']\n",
    "\n",
    "\n",
    "Y = np_utils.to_categorical(labels, num_classes)\n",
    "\n",
    "x,y = shuffle(img_data,Y, random_state=2)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=2)\n",
    "\n",
    "image_input = Input(shape=(224, 224, 3))\n",
    "\n",
    "model = VGG16(input_tensor=image_input, include_top=True,weights='imagenet')\n",
    "\n",
    "model.summary()\n",
    "\n",
    "last_layer = model.get_layer('fc2').output\n",
    "\n",
    "out = Dense(num_classes, activation='softmax', name='output')(last_layer)\n",
    "MagikModel = Model(image_input, out)\n",
    "MagikModel.summary()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for layer in MagikModel.layers[:-1]:\n",
    "\tlayer.trainable = False\n",
    "\n",
    "\n",
    "MagikModel.compile(loss='categorical_crossentropy',optimizer='rmsprop',metrics=['accuracy'])\n",
    "\n",
    "MagikModel.summary()\n",
    "\n",
    "\n",
    "\n",
    "t=time.time()\n",
    "train = MagikModel.fit(X_train, y_train, batch_size=32, epochs=50, verbose=1, validation_data=(X_test, y_test))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "(loss, accuracy) = MagikModel.evaluate(X_test, y_test, batch_size=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
